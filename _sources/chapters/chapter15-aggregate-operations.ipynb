{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fleet-preparation",
   "metadata": {},
   "source": [
    "```{figure} ../images/banner.png\n",
    "---\n",
    "align: center\n",
    "name: banner\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-charger",
   "metadata": {},
   "source": [
    "# Chapter 15 : Aggregate Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-reputation",
   "metadata": {},
   "source": [
    "## Chapter Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-pollution",
   "metadata": {},
   "source": [
    "- Various data operations on columns containing map. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-scholar",
   "metadata": {},
   "source": [
    "## Chapter Outline\n",
    "\n",
    "- [1. Dataframe Aggregation](#1)\n",
    "    - [1a. agg](#2)\n",
    "    - [1b. avg](#3)\n",
    "    - [1c. count](#4)\n",
    "    - [1d. max](#5)\n",
    "    - [1e. min](#6)\n",
    "    - [1f. mean](#7)\n",
    "    - [1g. sum](#8)\n",
    "    - [1g. pivot](#8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vital-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "from IPython.display import display_html\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html(index=False)\n",
    "        html_str+= \"\\xa0\\xa0\\xa0\"*10\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "space = \"\\xa0\" * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cutting-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      require([], function() {\n",
       "      })\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "\tif (!js_urls.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.3/dist/panel.min.js\"];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/dataframe.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      require([], function() {\n      })\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n\tif (!js_urls.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.3/dist/panel.min.js\"];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/dataframe.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "css = \"\"\"\n",
    "div.special_table + table, th, td {\n",
    "  border: 3px solid orange;\n",
    "}\n",
    "\"\"\"\n",
    "pn.extension(raw_css=[css])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-defense",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-outline",
   "metadata": {},
   "source": [
    "##  Chapter Outline - Gallery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-local",
   "metadata": {},
   "source": [
    "<div class=\"special_table\"></div>\n",
    "\n",
    "Click on any of the image below                 |To come back to this image gallery, on the top right corner under contents, click on Chapter Outline - Gallery\" \n",
    "- | - \n",
    "[![alt](img/chapter9/1.png)](#2)| [![alt](img/chapter9/2.png)](#3)\n",
    "[![alt](img/chapter9/3.png)](#4)| [![alt](img/chapter9/4.png)](#5)\n",
    "[![alt](img/chapter9/5.png)](#6)| [![alt](img/chapter9/6.png)](#7)\n",
    "[![alt](img/chapter9/7.png)](#8)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-parks",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-grain",
   "metadata": {},
   "source": [
    "## 1a. DataFrame Aggregations\n",
    "\n",
    "Explanation here.\n",
    "\n",
    "```{figure} img/chapter9/1a.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stock-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>region</th>\n",
       "      <th>sales</th>\n",
       "      <th>customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>north</td>\n",
       "      <td>100</td>\n",
       "      <td>walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>300</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>200</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>east</td>\n",
       "      <td>200</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>north</td>\n",
       "      <td>100</td>\n",
       "      <td>walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>300</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>north</td>\n",
       "      <td>200</td>\n",
       "      <td>walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>east</td>\n",
       "      <td>500</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>400</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id region  sales customer\n",
       "0       1  north    100  walmart\n",
       "1       2  south    300    apple\n",
       "2       3   west    200   google\n",
       "3       1   east    200   google\n",
       "4       2  north    100  walmart\n",
       "5       3   west    300    apple\n",
       "6       1  north    200  walmart\n",
       "7       2   east    500   google\n",
       "8       3   west    400    apple"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame([(1,\"north\",100,\"walmart\"),(2,\"south\",300,\"apple\"),(3,\"west\",200,\"google\"),\n",
    "                            (1,\"east\",200,\"google\"),(2,\"north\",100,\"walmart\"),(3,\"west\",300,\"apple\"),\n",
    "                            (1,\"north\",200,\"walmart\"),(2,\"east\",500,\"google\"),(3,\"west\",400,\"apple\"),],\n",
    "                          [\"emp_id\",\"region\",\"sales\",\"customer\"])\n",
    "                     \n",
    "df.toPandas()#show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "herbal-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " emp_id region  sales customer\n",
      "      2  south    300    apple\n",
      "      3   west    300    apple\n",
      "      3   west    400    apple\n",
      "      3   west    200   google\n",
      "      1   east    200   google\n",
      "      2   east    500   google\n",
      "      1  north    100  walmart\n",
      "      2  north    100  walmart\n",
      "      1  north    200  walmart\n"
     ]
    }
   ],
   "source": [
    "print(df.sort('customer').toPandas().to_string(index=False))#show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-forest",
   "metadata": {},
   "source": [
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-characteristic",
   "metadata": {},
   "source": [
    "## 1b. How to read individual elements of a map column ?\n",
    "\n",
    "\n",
    "```{figure} img/chapter9/1b.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-sound",
   "metadata": {},
   "source": [
    "<b>Input:  Spark dataframe containing map column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fleet-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(sales)|\n",
      "+----------+\n",
      "|      2300|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sound-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(sales)|\n",
      "+----------+\n",
      "|       100|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "given-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(sales)|\n",
      "+----------+\n",
      "|       500|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "valid-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(sales)|\n",
      "+------------+\n",
      "|           9|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "radical-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(sales)|\n",
      "+------------------+\n",
      "|255.55555555555554|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "photographic-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n",
      "|        avg(sales)|count(customer)|\n",
      "+------------------+---------------+\n",
      "|255.55555555555554|              9|\n",
      "+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"sales\": \"mean\",\"customer\":\"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "weighted-drink",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "all exprs should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0ca02063a9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sales\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/sparkbook/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \"\"\"\n\u001b[0;32m-> 1546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sparkbook/lib/python3.8/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[1;32m    114\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n",
      "\u001b[0;31mAssertionError\u001b[0m: all exprs should be Column"
     ]
    }
   ],
   "source": [
    "df.agg(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-blues",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-friendly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "insured-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>sum(sales)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id  sum(sales)\n",
       "0       1         500\n",
       "1       2         900\n",
       "2       3         900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"emp_id\").agg({\"sales\": \"sum\"}).orderBy('emp_id').toPandas()#show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "piano-rally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>max(sales)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id  max(sales)\n",
       "0       1         200\n",
       "1       2         500\n",
       "2       3         400"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"emp_id\").agg({\"sales\": \"max\"}).orderBy('emp_id').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "furnished-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>last(sales)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id  last(sales)\n",
       "0       1          200\n",
       "1       2          500\n",
       "2       3          400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"emp_id\").agg({\"sales\": \"last\"}).orderBy('emp_id').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-genetics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-mouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cellular-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|region|sum(sales)|\n",
      "+------+----------+\n",
      "|  east|       700|\n",
      "| north|       400|\n",
      "| south|       300|\n",
      "|  west|       900|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"region\").agg({\"sales\": \"sum\"}).orderBy('region').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "champion-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|customer|sum(sales)|\n",
      "+--------+----------+\n",
      "|   apple|      1000|\n",
      "|  google|       900|\n",
      "| walmart|       400|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"customer\").agg({\"sales\": \"sum\"}).orderBy('customer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-brighton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hired-observer",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe containing map keys as column and its value </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "black-architect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_map = df1.select(df1.data.a.alias(\"a\"), df1.data.b.alias(\"b\"), df1.data.c.alias(\"c\") )\n",
    "df_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-isolation",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "selected-accent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{'a': 1, 'b': 2, 'c': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df1.toPandas(),df_map.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-berry",
   "metadata": {},
   "source": [
    "<a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-titanium",
   "metadata": {},
   "source": [
    "## 1c. How to extract the keys from a map column?\n",
    "\n",
    "\n",
    "```{figure} img/chapter9/1c.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-coaching",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.map_keys(col)</b>\n",
    "\n",
    "Returns an unordered array containing the keys of the map.\n",
    "\n",
    "\n",
    "<b>Parameters</b>:\n",
    "\n",
    "- col – name of column or expression\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-october",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame consisting of a map column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "convenient-toddler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|data                  |\n",
      "+----------------------+\n",
      "|[a -> 1, b ->, c -> 3]|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame([({\"a\":1,\"b\":\"2\",\"c\":3},)],[\"data\"])\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-slide",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame consisting of a column of keys </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fatal-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     keys|\n",
      "+---------+\n",
      "|[a, b, c]|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "df_keys = df2.select(map_keys(df2.data).alias(\"keys\"))\n",
    "df_keys.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-acting",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "everyday-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                      output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{'a': 1, 'b': None, 'c': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[a, b, c]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"input                     \",            \"output\")\n",
    "display_side_by_side(df2.toPandas(),df_keys.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-pregnancy",
   "metadata": {},
   "source": [
    "<a id='5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-beach",
   "metadata": {},
   "source": [
    "## 1d. How to extract the values from a map column?\n",
    "\n",
    "Explanation here.\n",
    "\n",
    "```{figure} img/chapter9/1d.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-finish",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "\n",
    "<b>pyspark.sql.functions.array_except(col1, col2)</b>\n",
    "\n",
    "returns an array of the elements in col1 but not in col2, without duplicates.\n",
    " \n",
    "\n",
    "<b>Parameters</b>\n",
    "- col1 – name of column containing array\n",
    "- col2 – name of column containing array\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-canon",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame consisting of a map column  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "floral-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|data                  |\n",
      "+----------------------+\n",
      "|[a -> 1, b ->, c -> 3]|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame([({\"a\":1,\"b\":\"2\",\"c\":3},)],[\"data\"])\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-source",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame consisting of a column of values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ideal-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| values|\n",
      "+-------+\n",
      "|[1,, 3]|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_values\n",
    "df_values = df3.select(map_values(df3.data).alias(\"values\"))\n",
    "df_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-canada",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afraid-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{'a': 1, 'b': None, 'c': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[1, None, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df3.toPandas(),df_values.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-luxury",
   "metadata": {},
   "source": [
    "<a id='6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-idaho",
   "metadata": {},
   "source": [
    "## 1e. How to convert a map column into an array column?\n",
    "\n",
    "Explanation here.\n",
    "\n",
    "```{figure} img/chapter9/1e.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-superintendent",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.array_sort(col)</b>\n",
    "\n",
    "sorts the input array in ascending order. The elements of the input array must be orderable. Null elements will be placed at the end of the returned array.\n",
    "\n",
    "<b>Parameters</b>\n",
    "- col – name of column or expression\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-hygiene",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with map column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "outer-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|data                    |\n",
      "+------------------------+\n",
      "|[a -> 1, b -> 2, c -> 3]|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.createDataFrame([({\"a\":1,\"b\": 2,\"c\":3},)],[\"data\"])\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-madison",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe containing an array</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "finnish-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|array                   |\n",
      "+------------------------+\n",
      "|[[a, 1], [b, 2], [c, 3]]|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_entries\n",
    "df_array = df4.select(map_entries(df4.data).alias(\"array\"))\n",
    "df_array.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-evans",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "enclosed-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{'a': 1, 'b': 2, 'c': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[(a, 1), (b, 2), (c, 3)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df4.toPandas(),df_array.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-jonathan",
   "metadata": {},
   "source": [
    "<a id='7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-laptop",
   "metadata": {},
   "source": [
    "## 1f. How to create a map column from multiple array columns?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter9/1f.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-action",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.map_from_arrays(col1, col2)</b>\n",
    "\n",
    "Creates a new map from two arrays.\n",
    "\n",
    "<b>Parameters</b>\n",
    "- col1 – name of column containing a set of keys. All elements should not be null\n",
    "- col2 – name of column containing a set of values\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-lodge",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "opponent-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|     k|     v|\n",
      "+------+------+\n",
      "|[2, 5]|[a, b]|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = spark.createDataFrame([([2, 5], ['a', 'b'])], ['k', 'v'])\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-kennedy",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame with a column of array of repeated values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fluid-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|             map|\n",
      "+----------------+\n",
      "|[2 -> a, 5 -> b]|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_from_arrays\n",
    "df_map1 = df5.select(map_from_arrays(df5.k, df5.v).alias(\"map\"))\n",
    "df_map1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-housing",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "armed-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>[a, b]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{5: 'b', 2: 'a'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df5.toPandas(),df_map1.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-longer",
   "metadata": {},
   "source": [
    "<a id='8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-accommodation",
   "metadata": {},
   "source": [
    "## 1g. How to combine multiple map columns into one?\n",
    "\n",
    "Explanation here.\n",
    "\n",
    "```{figure} img/chapter9/1g.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-mineral",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.array_remove(col, element)</b>\n",
    "\n",
    "Remove all elements that equal to element from the given array.\n",
    "\n",
    "<b>Parameters</b>\n",
    "\n",
    "- col – name of column containing array\n",
    "- element – element to be removed from the array\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-narrow",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with multiple map columns </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "spectacular-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|            map1|    map2|\n",
      "+----------------+--------+\n",
      "|[1 -> a, 2 -> b]|[3 -> c]|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = spark.sql(\"SELECT map(1, 'a', 2, 'b') as map1, map(3, 'c') as map2\")\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-difference",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame with an array column with an element removed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "seasonal-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|combined_map            |\n",
      "+------------------------+\n",
      "|[1 -> a, 2 -> b, 3 -> c]|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_concat\n",
    "df_com = df6.select(map_concat(\"map1\", \"map2\").alias(\"combined_map\"))\n",
    "df_com.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-tyler",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "responsible-exhibit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>map1</th>\n",
       "      <th>map2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{1: 'a', 2: 'b'}</td>\n",
       "      <td>{3: 'c'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>combined_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{1: 'a', 2: 'b', 3: 'c'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df6.toPandas(),df_com.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-sleeve",
   "metadata": {},
   "source": [
    "<a id='9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-warren",
   "metadata": {},
   "source": [
    "<a id='9'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
